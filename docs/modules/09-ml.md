---
layout: default
title: "09: Machine Learning"
parent: Modules
nav_order: 9
permalink: /modules/09-ml
---

# Module 9: Machine Learning
{: .fs-9 }

Traditional machine learning algorithms in OpenCV for classification and clustering.
{: .fs-6 .fw-300 }

---

## Topics Covered

- K-Nearest Neighbors (KNN)
- Support Vector Machines (SVM)
- K-Means clustering
- Decision Trees

---

## Algorithm Explanations

### 1. K-Nearest Neighbors (KNN)

```
┌─────────────────────────────────────────────────────────────────────┐
│                    K-Nearest Neighbors (K=3)                        │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│         Class A (●)         Class B (○)                            │
│                                                                     │
│              ●                                                      │
│                    ○                        ○                       │
│         ●               ╭─────╮                                    │
│                        ╱   ●   ╲      New point: ★                │
│              ○       ╱    ★    ╲                                   │
│                     │      ○    │     Find 3 nearest neighbors     │
│         ●          │     ●      │     • 2 are ●(Class A)           │
│                      ╲         ╱      • 1 is ○(Class B)            │
│                        ╲     ╱        Majority vote → Class A      │
│              ○           ╰───╯                                      │
│                                   ○                                 │
│         ●                                                           │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

**Parameter Selection**:
- Small K: More sensitive to noise
- Large K: Smoother decision boundary
- Typical values: 3, 5, 7 (odd numbers avoid ties)

---

### 2. Support Vector Machines (SVM)

```
┌─────────────────────────────────────────────────────────────────────┐
│                    SVM: Maximum Margin Classifier                   │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│   Bad Boundary           Better Boundary        Optimal (SVM)      │
│                                                                     │
│   ●  ●  │  ○  ○          ●  ●  │  ○  ○         ●  ●  ┃  ○  ○      │
│   ●  ●  │  ○  ○          ●  ●  │  ○  ○         ●  ●  ┃  ○  ○      │
│   ●  ●  │  ○  ○          ●  ●   │  ○  ○        ●  ●  ┃  ○  ○      │
│   ●  ●  │  ○  ○          ●  ●    │  ○  ○       ●  ●  ┃  ○  ○      │
│   ●  ●  │  ○  ○          ●  ●      │  ○  ○     ●  ●  ┃  ○  ○      │
│         │                         │                  ┃              │
│   Separates but          Separates               Maximum           │
│   narrow margin          good margin             margin!           │
│                                                                     │
│                         ◀──margin──▶                               │
│                         ●          ○  ← Support vectors            │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

**Kernel Functions**:

| Kernel | Use Case |
|:-------|:---------|
| Linear | Linearly separable data |
| RBF | General purpose (most common) |
| Polynomial | Polynomial boundaries |

---

### 3. K-Means Clustering

```
┌─────────────────────────────────────────────────────────────────────┐
│                    K-Means Algorithm Steps                          │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│   Step 1: Init          Step 2: Assign         Step 3: Update     │
│                                                                     │
│   ○ ○    ○ ○            ● ●    ○ ○            ● ●    ○ ○          │
│    ○  ★₁  ○               ●  ★₁  ○               ●   ★₁ ○          │
│                                                                     │
│   ○ ○     ○ ○           ● ●     ○ ○           ● ●     ○ ○         │
│      ★₂  ○ ○               ★₂  ○ ○               ★₂   ○ ○         │
│                                                                     │
│   Random               Points assigned      Centroids move        │
│   centroids ★          to nearest ★         to cluster mean       │
│                                                                     │
│   Repeat Steps 2-3 until convergence                               │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

**Elbow Method for K Selection**:
```
   Distortion
      ▲
      │ ╲
      │  ╲
      │   ╲───── "elbow" = optimal K
      │      ╲____
      │           ╲____
      └─────────────────────▶
        1   2   3   4   5   K
```

---

### 4. Decision Trees

```
┌─────────────────────────────────────────────────────────────────────┐
│                    Decision Tree Structure                          │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│                     [Feature 1 > 5?]                               │
│                      /           \                                  │
│                   Yes             No                                │
│                    /               \                                │
│           [Feature 2 > 3?]    [Feature 3 > 2?]                    │
│            /        \          /        \                          │
│          Yes        No       Yes        No                         │
│           │          │        │          │                          │
│        [Class A]  [Class B] [Class A] [Class C]                   │
│                                                                     │
│   Split criteria: Information Gain or Gini Impurity               │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

---

## Tutorial Files

| File | Description |
|:-----|:------------|
| `01_ml_basics.py` | KNN, SVM, K-Means, Decision Trees |

---

## Key Functions Reference

| Function | Description |
|:---------|:------------|
| `cv2.ml.KNearest_create()` | Create KNN classifier |
| `cv2.ml.SVM_create()` | Create SVM classifier |
| `cv2.kmeans()` | K-Means clustering |
| `cv2.ml.DTrees_create()` | Create Decision Tree |
| `model.train()` | Train model |
| `model.predict()` | Make predictions |

---

## Further Reading

- [OpenCV ML Module](https://docs.opencv.org/4.x/d6/de2/tutorial_py_table_of_contents_ml.html)
